name: Mission JSON Validate

on:
  workflow_call:
  workflow_dispatch:
  push:
    paths:
      - 'src/**'
      - 'schemas/**'
      - '.github/workflows/mission-validate.yml'
  pull_request:

jobs:
  mission-validate:
    runs-on: ubuntu-latest
    env:
      ACTIONS_RUNNER_DEBUG: true
      ACTIONS_STEP_DEBUG: true
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - name: Install deps
        run: |
          python -m pip install -U pip
          python -m pip install -r requirements.txt jsonschema pandas numpy matplotlib
      - name: Install test dependencies
        run: |
          pip install -r requirements-test.txt || true
      - name: Log Python version
        run: python --version
      - name: Check disk space
        run: df -h
      - name: FTL analysis timestamp
        run: |
          echo "FTL analysis timestamp: 2025-08-14 20:38 PDT"
      - name: Run tiny mission and export JSON + perf CSV
        run: |
          PYTHONPATH=src python -m impulse.mission_cli --waypoints examples/waypoints/simple.json --export mission.json --perf-csv perf.csv --hybrid simulate-first
      - name: Validate mission.json against schema
        run: |
          python bin/validate_mission_json.py mission.json
      - name: Check artifact size (workspace)
        run: |
          echo "Checking artifact size (workspace): 2025-08-14 19:53 PDT"
          du -sh .
          SIZE=$(du -sb . | cut -f1)
          if [ "$SIZE" -gt 2147483648 ]; then
            echo "Artifacts exceed 2GB limit: $SIZE bytes"
            exit 1
          fi
      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mission-export
          path: |
            mission.json
            perf.csv
          retention-days: 30

  perf-aggregate:
    needs: mission-validate
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - name: Install deps
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq
          python -m pip install -U pip
          python -m pip install -r requirements.txt pandas numpy matplotlib
      - name: Log Python version (pre-UQ)
        run: python --version
      - name: Download perf.csv artifact
        uses: actions/download-artifact@v4
        with:
          name: mission-export
          path: ./artifacts
      - name: Plot perf summary
        run: |
          python bin/plot_perf_csv.py --csv ./artifacts/perf.csv --out perf_summary.png
      - name: Aggregate perf summary JSON
        run: |
          # Simulate multiple runs if only one CSV is present
          cp ./artifacts/perf.csv ./artifacts/perf_run2.csv
          python bin/aggregate_perf_csv.py ./artifacts/perf.csv ./artifacts/perf_run2.csv --out perf_aggregate.json
      - name: Validate CSVs
        run: |
          echo "Validating CSVs: 2025-08-14 20:38 PDT"
          python - <<'PY'
          import pandas as pd
          df1 = pd.read_csv('data/dist_profile_40eridani.csv', comment='#')
          assert not df1.empty, 'Standard CSV empty'
          df2 = pd.read_csv('data/dist_profile_40eridani_varied.csv', comment='#')
          assert not df2.empty, 'Varied CSV empty'
          print('CSV rows:', len(df1), len(df2))
          PY
      - name: Log UQ input
        run: |
          echo "UQ input: 2025-08-14 20:38 PDT"
          head -n 5 data/dist_profile_40eridani_varied.csv || true
      - name: Validate CSV columns
        run: |
          echo "Validating CSV columns: 2025-08-14 20:10 PDT"
          python - <<'PY'
          import pandas as pd
          df = pd.read_csv('data/dist_profile_40eridani.csv', comment='#')
          assert len(df.columns) > 0, 'Standard CSV has no columns'
          dfv = pd.read_csv('data/dist_profile_40eridani_varied.csv', comment='#')
          assert len(dfv.columns) > 0, 'Varied CSV has no columns'
          assert 'energy' in dfv.columns, 'Missing energy column in varied CSV'
          print('CSV columns OK:', list(df.columns), list(dfv.columns))
          PY
      - name: Check disk space (pre-UQ)
        run: df -h
      - name: 40 Eridani A UQ + analysis (100 samples)
        timeout-minutes: 15
        run: |
          PYTHONPATH=src python -m src.uq_validation.impulse_uq_runner --samples 100 --seed 123 --out uq_summary.json --jsonl-out uq_records.jsonl --dist-profile data/dist_profile_40eridani.csv
          python bin/plot_uq_records.py --records uq_records.jsonl --energy-out 40eridani_energy.png --feas-out 40eridani_feasibility.png --bins 15
      - name: Generate extended 40 Eridani plots
        run: |
          python bin/plot_uq_records.py --records uq_records.jsonl --energy-out 40eridani_energy_extended.png --feas-out 40eridani_feasibility_extended.png --bins 30
      - name: Log matplotlib version
        run: python -m pip show matplotlib
      - name: Generate plots (retry helper)
        run: |
          echo "Generating plots: 2025-08-14 20:38 PDT"
          for attempt in 1 2 3; do
            PYTHONPATH=src python -m src.uq_validation.plot_uq_records && break
            echo "Plot retry $attempt failed; waiting 5s"
            sleep 5
          done
          ls artifacts/40eridani_*.png || { echo "No PNGs generated"; exit 1; }
      - name: Log plot generation
        run: |
          echo "Generating plots (listing): 2025-08-14 20:38 PDT"
          ls -1 *.png || true
          ls -1 artifacts/*.png || true
      - name: Validate PNG presence
        run: |
          echo "Checking PNGs: 2025-08-14 20:38 PDT"
          ls artifacts/40eridani_*.png || { echo "No PNGs in artifacts"; exit 1; }
      - name: Generate fallback PNGs
        if: failure()
        run: |
          echo "Generating fallback PNGs: 2025-08-14 20:38 PDT"
          mkdir -p artifacts
          python - <<'PY'
          import matplotlib
          matplotlib.use('Agg')
          import matplotlib.pyplot as plt
          plt.figure()
          plt.text(0.5, 0.5, 'Fallback Plot', ha='center', va='center')
          plt.savefig('artifacts/40eridani_energy.png')
          PY
      - name: 40 Eridani A UQ with varied distance profile (100 samples)
        run: |
          PYTHONPATH=src python -m src.uq_validation.impulse_uq_runner --samples 100 --seed 123 --out uq_summary_varied.json --jsonl-out uq_records_varied.jsonl --dist-profile data/dist_profile_40eridani_varied.csv
          python bin/plot_uq_records.py --records uq_records_varied.jsonl --energy-out 40eridani_energy_varied.png --feas-out 40eridani_feasibility_varied.png --bins 20 --metrics-out uq_varied_metrics.json
      - name: Validate varied profile metrics against thresholds
        run: |
          echo "Validating varied profile metrics: 2025-08-14 20:38 PDT"
          python -c "import json;d=json.load(open('uq_varied_metrics.json'));cv=float(d.get('energy_cv',1.0));ff=float(d.get('feasible_fraction',0.0));assert cv<0.1,cv;assert ff>0.8,ff;print('Varied profile gates passed',{'cv':cv,'ff':ff})"
      - name: Prepare artifacts directory
        run: |
          echo "Preparing artifacts dir: 2025-08-14 20:38 PDT"
          mkdir -p artifacts
          cp -v perf_summary.png artifacts/
          cp -v perf_aggregate.json artifacts/
          cp -v uq_summary.json uq_records.jsonl artifacts/
          cp -v 40eridani_energy.png 40eridani_feasibility.png artifacts/
          cp -v 40eridani_energy_extended.png 40eridani_feasibility_extended.png artifacts/
          cp -v uq_summary_varied.json uq_records_varied.jsonl artifacts/
          cp -v 40eridani_energy_varied.png 40eridani_feasibility_varied.png artifacts/
          cp -v uq_varied_metrics.json artifacts/
      - name: Validate artifact contents
        run: |
          echo "Validating artifacts: 2025-08-14 20:38 PDT"
          for file in 40eridani_energy.png 40eridani_feasibility.png 40eridani_energy_extended.png 40eridani_feasibility_extended.png 40eridani_energy_varied.png 40eridani_feasibility_varied.png uq_varied_metrics.json; do
            [ -f "artifacts/$file" ] || { echo "Missing $file"; exit 1; }
          done
          echo "All expected artifacts present"
      - name: Check artifact integrity
        run: |
          echo "Checking artifact integrity: 2025-08-14 20:38 PDT"
          for file in artifacts/40eridani_*.png; do
            if [ -f "$file" ]; then
              file "$file" | grep -q "PNG image data" || { echo "$file not a valid PNG"; exit 1; }
            fi
          done
      - name: Check artifact size (artifacts dir)
        run: |
          echo "Checking artifact size: 2025-08-14 20:38 PDT"
          du -sh artifacts
          SIZE=$(du -sb artifacts | cut -f1)
          if [ "$SIZE" -gt 2147483648 ]; then
            echo "Artifacts exceed 2GB limit: $SIZE bytes"
            exit 1
          fi
      - name: Generate fallback artifacts
        if: failure()
        run: |
          echo "Generating fallback artifacts: 2025-08-14 20:38 PDT"
          mkdir -p artifacts
          for file in 40eridani_energy.png 40eridani_feasibility.png 40eridani_energy_extended.png 40eridani_feasibility_extended.png 40eridani_energy_varied.png 40eridani_feasibility_varied.png; do
            touch artifacts/$file
          done
          echo '{"energy_mean": 0, "energy_std": 0, "energy_cv": 0, "feasible_fraction": 0}' > artifacts/uq_varied_metrics.json
      - name: Upload perf summary
        uses: actions/upload-artifact@v4
        with:
          name: perf-summary
          path: perf_summary.png
      - name: Log artifact contents
        run: |
          echo "Listing artifacts before upload: 2025-08-14 19:53 PDT"
          ls -R artifacts/ || echo "Artifacts directory empty"
          ls -1 artifacts/*.png || true
      - name: Log artifacts to upload
        run: |
          echo "Uploading artifacts: 2025-08-14 19:53 PDT"
          ls -R artifacts
      - name: Upload 40 Eridani artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: 40eridani-artifacts
          path: artifacts/
          retention-days: 30
      - name: Notify on failure
        if: failure()
        run: |
          echo "Workflow failed: 2025-08-14 20:38 PDT. Check logs: gh run view ${{ github.run_id }} --repo ${{ github.repository }} --log"
      - name: Comment summary on PR
        if: github.event_name == 'pull_request'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Posting PR summary..."
          ENERGY=$(jq -r '.segment_energy_mean' perf_aggregate.json)
          TIME=$(jq -r '.segment_time_mean' perf_aggregate.json)
          FEAS=$(jq -r '.feasible_fraction // empty' uq_summary.json 2>/dev/null || echo "")
          BODY="Perf Aggregate Summary:%0A- Mean Segment Energy: ${ENERGY} J%0A- Mean Segment Time: ${TIME} s%0A- Feasible Fraction (UQ): ${FEAS}"
          if command -v gh >/dev/null 2>&1; then
            gh pr comment ${{ github.event.pull_request.number }} --body "$BODY"
          else
            echo "GitHub CLI not installed; skipping PR comment"
          fi
      - name: Comment on PR failure
        if: failure() && github.event_name == 'pull_request'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Commenting on PR: 2025-08-14 19:53 PDT"
          gh pr comment ${{ github.event.pull_request.number }} --body "Mission validation failed. Check logs: gh run view ${{ github.run_id }} --repo ${{ github.repository }} --log"
